{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbebcc43-058f-46dc-8891-4f5b2849831d",
   "metadata": {},
   "source": [
    "## VEHICLE DETECTION PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54e43b4-e425-4fec-bc93-4a0bba4086c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO('yolov8n.pt')\n",
    "vehicle_classes = {\"car\", \"truck\", \"bus\", \"motorbike\", \"motorcycle\", \"bicycle\"}\n",
    "\n",
    "# Parameters\n",
    "pos_linha = 550  # Line position for counting\n",
    "offset = 6       # Offset for line crossing detection\n",
    "largura_min = 80\n",
    "altura_min = 80\n",
    "pixels_to_meters = 0.1  # Calibration value (adjust as needed)\n",
    "speed_threshold = 30    # Speed limit in km/h\n",
    "\n",
    "# Tracking setup\n",
    "detec = []\n",
    "carros = 0\n",
    "vehicle_tracks = {}\n",
    "next_track_id = 0\n",
    "\n",
    "# Video input\n",
    "video_path = r\"C:\\Users\\HP\\Downloads\\video.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2(history=100, varThreshold=50)\n",
    "\n",
    "def calculate_speed(distance_pixels, time_seconds):\n",
    "    distance_meters = distance_pixels * pixels_to_meters\n",
    "    return (distance_meters / time_seconds) * 3.6  # m/s to km/h\n",
    "\n",
    "def pega_centro(x, y, w, h):\n",
    "    return x + w // 2, y + h // 2\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    fg_mask = bg_subtractor.apply(frame)\n",
    "    _, thresh = cv2.threshold(fg_mask, 200, 255, cv2.THRESH_BINARY)\n",
    "    dilated = cv2.dilate(thresh, np.ones((5, 5)))\n",
    "    contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    current_time = time.time()\n",
    "\n",
    "    results = model(frame)[0]\n",
    "\n",
    "    cv2.line(frame, (25, pos_linha), (1200, pos_linha), (255,127,0), 3)\n",
    "\n",
    "    for box in results.boxes.data.tolist():\n",
    "        x1, y1, x2, y2, conf, cls_id = box\n",
    "        label = model.names[int(cls_id)].lower()\n",
    "        if label not in vehicle_classes:\n",
    "            continue\n",
    "\n",
    "        x, y, w, h = int(x1), int(y1), int(x2 - x1), int(y2 - y1)\n",
    "        cx, cy = pega_centro(x, y, w, h)\n",
    "\n",
    "        # Bounding box & label\n",
    "        color = (255, 0, 0)\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "        cv2.putText(frame, f\"{label} {conf:.2f}\", (x, y - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "        # Count vehicle on line crossing\n",
    "        if (w >= largura_min and h >= altura_min):\n",
    "            detec.append((cx, cy))\n",
    "            for (dcx, dcy) in detec:\n",
    "                if pos_linha - offset < dcy < pos_linha + offset:\n",
    "                    carros += 1\n",
    "                    cv2.line(frame, (25, pos_linha), (1200, pos_linha), (0,127,255), 3)\n",
    "                    detec.remove((dcx, dcy))\n",
    "                    print(f\"Vehicle Counted: {carros}\")\n",
    "\n",
    "        # Speed Detection\n",
    "        matched_id = None\n",
    "        for track_id, data in vehicle_tracks.items():\n",
    "            px, py = data['last_position']\n",
    "            if np.linalg.norm([cx - px, cy - py]) < 50:\n",
    "                matched_id = track_id\n",
    "                break\n",
    "\n",
    "        if matched_id is None:\n",
    "            matched_id = next_track_id\n",
    "            vehicle_tracks[matched_id] = {\n",
    "                'last_position': (cx, cy),\n",
    "                'last_time': current_time,\n",
    "                'speed': 0\n",
    "            }\n",
    "            next_track_id += 1\n",
    "        else:\n",
    "            track = vehicle_tracks[matched_id]\n",
    "            time_diff = current_time - track['last_time']\n",
    "            if time_diff > 0:\n",
    "                pixel_distance = np.linalg.norm([cx - track['last_position'][0], cy - track['last_position'][1]])\n",
    "                speed = calculate_speed(pixel_distance, time_diff)\n",
    "                track['last_position'] = (cx, cy)\n",
    "                track['last_time'] = current_time\n",
    "                track['speed'] = speed\n",
    "\n",
    "                speed_text = f\"{speed:.1f} km/h\"\n",
    "                speed_color = (0, 0, 255) if speed > speed_threshold else (0, 255, 0)\n",
    "                cv2.putText(frame, speed_text, (x, y + h + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, speed_color, 2)\n",
    "\n",
    "    # Display count\n",
    "    cv2.putText(frame, f\"VEHICLE COUNT : {carros}\", (450, 70), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 5)\n",
    "\n",
    "    # Show windows\n",
    "    cv2.imshow(\"Vehicle Detection\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        print(\"Stopped by user.\")\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0d2f470-1ae9-4091-80b1-614c086c6636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edce24b-f932-41bf-866d-3808e164730c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
